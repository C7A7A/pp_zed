{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Uczenie głębokie cz. I\n",
    "\n",
    "Ten notatnik ma na celu przedstawienie jednego ze sposobów tworzenia głębokich sieci neuronowych w Pythonie. W trakcie zadania najpierw stworzymy prostą sieć konwolucyjną, a następnie zbadamy jej proces uczenia się. Na tych zajęciach wykorzystamy biblioteki [Keras](https://keras.io/) i [Tensorflow](https://www.tensorflow.org/).\n",
    "\n",
    "Po wykonaniu tego zadania powinieneś:\n",
    "+ wiedzieć z jakich części składają się sieci konwolucyjne,\n",
    "+ potrafić uruchomić sieć neuronową na własnych danych,\n",
    "+ wiedzieć jak wczytać i wykorzystać gotowy model,\n",
    "+ zwizualizować i śledzić na żywo proces uczenia się sieci."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prosta sieć konwolucyjna\n",
    "\n",
    "Najpierw załadujemy odpowiednie biblioteki i wczytamy mały zbiór obrazów do uczenia się rozpoznawania liczb. \n",
    "\n",
    "**Zad. 1:Przejrzyj komentarze przy operacjach `import`, aby zapoznać się z nazewnictwem w bibliotece Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(23)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Typ sieci\n",
    "from tensorflow.keras.models import Sequential # tworzymy typową sieć jednokierunkową (bez rekurencji)\n",
    "\n",
    "# Typy warstw\n",
    "from tensorflow.keras.layers import Dense # warstwa z w pełni połączona (wszystkie neurony z poprzedniej warstwy do każdego w kolejnej)\n",
    "from tensorflow.keras.layers import Dropout # mechanizm losowego wyłączania neuronów (pozwala uniknąć przeuczenia)\n",
    "from tensorflow.keras.layers import Activation # aktywacja, czyli funkcja przyjmująca jedną liczbę (np. sigmoid, softmax) \n",
    "from tensorflow.keras.layers import Flatten # spłaszczenie wejścia (np. zamiana tensora o wymiarach 64x32x32 na wektor o długości 65536)\n",
    "from tensorflow.keras.layers import Conv2D # warstwa konwolucyjna, tworzy filtry o zadanym rozmiarze w zadanych odstępach\n",
    "from tensorflow.keras.layers import MaxPooling2D # warstwa zmniejszająca obraz poprzez operacje max na zadanym rozmiarze pikseli\n",
    "\n",
    "# Optymalizator i funkcja straty\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "# \"Przydasie\"\n",
    "from tensorflow.keras import utils as k_utils\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czas na zbiór danych. Skorzystamy ze standardowego zbioru treningowego do omawiania sieci konwolucyjnych, czyli [MNIST](http://yann.lecun.com/exdb/mnist/). Zbiór składa się z małych obrazków, więc będziemy w stanie nauczyć sieć na zwykłym komputerze, a sieci konwolucyjne są tu jak najbardziej potrzebne do uzyskania sensownych wyników.\n",
    "\n",
    "Biblioteka Keras ma funkcję pobierającą ten zbiór z sieci, z czego skrzętnie skorzystamy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 2: Sprawdź jakie wymiary mają załadowane obrazki. Przypisz te wartości do zmiennych img_rows, img_cols. Sprawdź również liczbę klas i przypisz tę wartość to zmiennej `num_classes`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sprawdź wymiary zbioru danych\n",
    "\n",
    "# img_rows = ?\n",
    "# img_cols = ?\n",
    "# num_classes = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 3: Wyświetl pierwszy rysunek ze zbior.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(?, cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstępne przetwarzanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponieważ obrazy mogą mieć różną liczbę kolorów (kanałów), musimy powiedzieć Kerasowi jaki format danych będzie przetwarzać. Obrazy mogą mieć jeden kanał (skala szarości), trzy kanały (RGB), a czasami więcej niż trzy kanały (np. zdjęcia satelitarne). Dane w zbiorze MNIST są zakodowane w skali szarości, a zatem mają jeden kanał.\n",
    "\n",
    "**Zad. 4: Zmień wymiarowość danych wejściowych zgodnie z poniższym wzorem.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.reshape(X_train.shape[0], l_wierszy, l_kolumn, l_kanalow)\n",
    "# X_test = X_test.reshape(X_test.shape[0], l_wierszy, l_kolumn, l_kanalow)\n",
    "# input_shape = (l_wierszy, l_kolumn, l_kanalow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oprócz określenia wymiaru danych wejściowych musimy upewnić się, że są one typu `float32`. Ponadto warto ustandaryzować dane wejściowe lub sprowadzić je do zakresu [0-1]. My uczynimy to drugie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train = X_train.astype('float32')\n",
    "# X_test = X_test.astype('float32')\n",
    "# X_train /= 255\n",
    "# X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatnia rzecz, którą musimy zrobić to zakodować klasy (`y`) w sposób binarny. Czyli zamiast klas `1, 2, ... 10` itd., chcemy uzyskać kodowanie w postaci `[1 0 0 0 0 0 0 0 0 0], [0 1 0 0 0 0 0 0 0 0] ... [0 0 0 0 0 0 0 0 0 1]`. W Kerasie posłuży nam do tego funkcja `to_categorical()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = k_utils.to_categorical(y_train, num_classes)\n",
    "# y_test = k_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tworzenie sieci\n",
    "\n",
    "W Kerasie **architekturę sieci** definiuje się poprzez podanie typu sieci i kolejnych warstw. Dla każdej warstwy określa się typ neuronów, ich liczbę i (jeśli to konieczne) ich parametry.\n",
    "\n",
    "Poniżej zdefiujemy prostą sieć konwolucyjną. Będzie się ona składała tylko z dwóch warstw konwolucyjnych, bo zdjęcia na których operujemy są bardzo małe. Większe zdjęcia wymagałyby więcej warstw. Uwaga! W uporszczeniu: im większa sieć tym większe wymagania pamięciowe i czasowe!\n",
    "\n",
    "Nasza architektura to (porównaj z poniższym kodem):\n",
    "- **warstwa konwolucyjna** tworząca **32 filtry** o rozmiarze **3x3**. Każdy filtr stanowi wejście dla funkcji atywacyjnej typu **ReLU**. Zauważ, że w pierwszej warstwie sieci musimy podać wymiary (warstwę wejściową). W kolejnych warstwach nie jest to konieczne, bo warstwy wiedzą jak mają się łączyć.\n",
    "- **warstwa konwolucyjna** tworząca **64 filtry** o rozmiarze **3x3** z **ReLU**. \n",
    "- **warstwa pooling** zmiejszająca obraz o połowę\n",
    "- **warstwa dropout** losowo wyłączają 1/4 neuronów przy każdym przejściu\n",
    "- **warstwę spłaszczającą** wielowymiarowe konwolucje w wektor\n",
    "- **w pełni połączona warstwa** 128 neuronów\n",
    "- **kolejny dropout**\n",
    "- **warstwa wyjściowa** posiadającą tyle neuronów ile mamy klas\n",
    "\n",
    "**Zad. 5: W ostatniej warstwie nie podałem funkcji aktywacji. Wróć do slajdów i sprawdź jaka funkcja aktywacji nada się do klasyfikacji.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Dense(num_classes, activation='?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po stworzeniu sieci w Kerasie trzeba ją skompilować. W tym kroku Keras dostosowuje kod pod wykonanie na wybranym backendzie. W naszym przypadku będzie to Tensorflow, ale równie dobrze mogłyby to być platformy Theano lub CNTK.\n",
    "\n",
    "Podczas kompilacji podajemy **funkcję straty**, **optymalizator**. Ponadto można podać szereg miar do śledzenia (typowo przy klasyfikacji accuracy).\n",
    "\n",
    "**Zad. 6: Wróć do slajdów i sprawdź jaka funkcja straty nada się do klasyfikacji wieloklasowej. Jako optymalizator wybierz Adadelta, dzięki temu nie będziesz musiał podawać learning rate. Protip: użyj Tab.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=losses.?,\n",
    "#               optimizer=optimizers.?,\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uczenie sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mamy sieć. Teraz nic tylko odpalić uczenie. Robiąc to musimy podać **batch_size** (czyli ile przykładów przepuszczamy przez sieć między aktualizacją wag) i liczbę **epok** (czyli ile razy chcemy przepuścić przez sieć cały zbiór danych). Zbiór walidacyjny będzie nam mówił na ile dobrze sieć działa na danych, których wcześniej nie widzieliśmy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train,\n",
    "#           batch_size=128,\n",
    "#           epochs=12,\n",
    "#           verbose=1,\n",
    "#           validation_data=(X_test, y_test))\n",
    "\n",
    "# Jak kod ruszy, oszacuj ile zajmie uczenie sieci (ETA jednej epoki x liczba epok).\n",
    "# Jeśli wychodzi Ci więcej niż 3 minuty zatrzymaj uczenie i czytaj dalej..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spójrzmy na ETA. Aha, ale to tylko 1 epoka z 12... Hmmm.... Trochę będzie trzeba poczekać. Zatrzymaj powyższy blok kodu. Zaraz coś z tym zrobimy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU\n",
    "\n",
    "Uczenie sieci to bardzo czasochłonny proces. Na szczeście, ze względu na swoją modularność, sieci bardzo łatwo się zrównolegla. Stąd gotowość większości bibliotek do współpracy z kartami graficznymi (jednakże obecnie są to praktycznie tylko karty NVidii).\n",
    "\n",
    "Ponieważ prawdopodobnie nie masz komputera z super-ekstra kartą graficzną do obliczeń równoległych, skorzystamy z karty graficznej w chmurze. AWS, Google Cloud, Microsoft Azure chętnie udostępnią swoje moce obliczeniowe za drobną opłatą. Maszyny wirtualne z GPU są stosunkowo drogie w porównaniu do innych maszyn, ale przy naliczaniu godzinowym (a niekiedy sekundowym) jest to bardzo interesująca opcja. Jeśli masz dostęp do jednej z tych platform, albo lepiej dostęp i niewykorzystany kredyt, warto z tego skorzystać.\n",
    "\n",
    "Aby zaoszczędzić sobie czasu nie będziemy stawiać pełnoprawnych wirtualek na żadnej z wymienionych platform. Zamiast tego proponuję szybko odpalić Google Colab (https://colab.research.google.com/) i tam wgrać ten notebook.\n",
    "\n",
    "**Zad 7. Wykonaj powyższe kroki i naucz sieć z tego notebooka na GPU. Po zakończeniu obliczeń zapisz model do pliku za pomocą poniższego kodu. Następnie ściągnij utworzony plik modelu z Crestle i zamknij zdalnego Jupytera.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"gpu_cnn_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytywanie modelu i predykcje\n",
    "\n",
    "Uczenie się trwa długo, ale jak już mamy nauczoną sieć to wcale nie zajmuje ona aż tyle miejsca na dysku i działa bardzo szybko. Sprawdźmy czy tak rzeczywiście jest.\n",
    "\n",
    "**Zad. 8: Wczytaj model nauczony na GPU na swoim lokalnym komputerze i dokonaj predykcji zgodnie z poniższym szablonem.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# gpu_model = load_model(\"gpu_cnn_model\") # w razie co do projektu jest też załączony wcześniej nauczony \"cnn_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# score = gpu_model.evaluate(X_test, y_test, verbose=0)\n",
    "# print('{0} przykładów'.format(X_test.shape[0]))\n",
    "# print('loss={0:.4f}, accuracy={1:.4f}'.format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U mnie na laptopie wyszło ok. 9 sekund. Dzieląc to przez liczbę przykładów wychodzi 10000/9 = 1111 obrazów na sekundę, czyli nie tak źle. Zwłaszcza, że mój komputer ma ponad 5 lat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow udostępnia świetne narzędzie do wizualizacji procesu uczenia sieci o nazwie **Tensorboard**. Aby je uruchomić odpal Anaconda Prompt i wpisz następujące polecenie:\n",
    "\n",
    "```\n",
    "tensorboard --logdir=\"pelna_sciezka_do_tego_notebooka/logs\"\n",
    "```\n",
    "\n",
    "**Zad. 9: Odpal Tensorboarda a następnie uruchom (lokalnie) poniższy kod. W trakcie gdy sieć się uczy wejdź na stronę Tensorboard i sledź zmiany.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 12\n",
    "# batch_size = 128\n",
    "# dataset_size = 1000\n",
    "\n",
    "# # Protip: w nazwie modelu zawrzyj wartości parametrów, wtedy będzie można łatwo porównywać różne architektury/parametry\n",
    "# model_name = \"cpu_cnn_model\" + \\\n",
    "#     \"_e=\" + str(epochs) + \"_b=\" + str(batch_size) + \\\n",
    "#     \"_n=\" + str(dataset_size) + \"_t=\" + time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "\n",
    "# tb_callback = TensorBoard(log_dir=\"./logs/\" + model_name, batch_size=128, histogram_freq=-1,\n",
    "#                           write_graph=True, write_images=False)\n",
    "\n",
    "# model.fit(X_train[:dataset_size,:,:,:], y_train[:dataset_size,:],\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(X_test[:dataset_size,:,:,:], y_test[:dataset_size,:]),\n",
    "#           callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zad. 10: Zmień batch size na 64, zbuduj i skompiluj ponownie sieć (kod z zad. 5 i 6) i odpal uczenie jeszcze raz. Porównaj krzywe uczenia w Tensorboard.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poznałeś podstawy tego co jest potrzebne aby nauczyć własną głęboką sieć neuronową od zera. O tym jakie inne architektury zaproponowano do różnych zadań i jak przyspieszyć proces uczenia sieci dla wielu standardowych problemów dowiesz się na następnych zajęciach."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
